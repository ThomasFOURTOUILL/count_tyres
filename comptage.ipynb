{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44edd539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.218 üöÄ Python-3.11.13 torch-2.9.0+cu128 CPU (13th Gen Intel Core i7-1360P)\n",
      "Setup complete ‚úÖ (16 CPUs, 15.4 GB RAM, 85.8/1006.9 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba25577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics Solutions: ‚úÖ {'source': None, 'model': 'yolo11n.pt', 'classes': None, 'show_conf': True, 'show_labels': True, 'region': [(20, 400), (1080, 400), (1080, 360), (20, 360)], 'colormap': 21, 'show_in': True, 'show_out': True, 'up_angle': 145.0, 'down_angle': 90, 'kpts': [6, 8, 10], 'analytics_type': 'line', 'figsize': (12.8, 7.2), 'blur_ratio': 0.5, 'vision_point': (20, 20), 'crop_dir': 'cropped-detections', 'json_file': None, 'line_width': 2, 'records': 5, 'fps': 30.0, 'max_hist': 5, 'meter_per_pixel': 0.05, 'max_speed': 120, 'show': True, 'iou': 0.7, 'conf': 0.25, 'device': None, 'max_det': 300, 'half': False, 'tracker': 'botsort.yaml', 'verbose': True, 'data': 'images'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 500x900 21.1ms, 2 potted plant\n",
      "Speed: 99.8ms track, 21.1ms solution per image at shape (1, 3, 500, 900)\n",
      "\n",
      "Video frame is empty or video processing has been successfully completed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "from ultralytics import solutions\n",
    "\n",
    "# Open the video file\n",
    "# cap = cv2.VideoCapture(\"data/rack_3.mp4\")\n",
    "# cap = cv2.VideoCapture(\"data/cartons.jpg\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "# Get video properties: width, height, and frames per second (fps) (Obtenir les propri√©t√©s de la vid√©o¬†: largeur, hauteur et images par seconde (ips))\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define points for a line or region of interest in the video frame (D√©finir les points d'une ligne ou d'une zone d'int√©r√™t dans l'image vid√©o)\n",
    "# region_points = [(20, 400), (1080, 400)]   # line counting\n",
    "region_points = [(20, 400), (1080, 400), (1080, 360), (20, 360)]  # rectangle region\n",
    "# region_points = [(20, 400), (1080, 400), (1080, 360), (20, 360), (20, 400)]   # polygon region\n",
    "\n",
    "# Initialize the video writer to save the output video (Initialiser le graveur vid√©o pour enregistrer la vid√©o de sortie)\n",
    "video_writer = cv2.VideoWriter(\"data/object_counting_output.avi\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Initialize the Object Counter with visualization options and other parameters (Initialiser le compteur d'objets avec les options de visualisation et autres)\n",
    "counter = solutions.ObjectCounter(\n",
    "    show=True,  # Display the image during processing (Afficher l'image pendant le traitement)\n",
    "    region=region_points,  # Region of interest points (Points de la r√©gion d'int√©r√™t)\n",
    "    # region=line_points,  # on aurait pris cette ligne si on avait choisi des lignes\n",
    "    model=\"yolo11n.pt\",  # Ultralytics YOLO11 model file (Fichier mod√®le Ultralytics YOLO11)\n",
    "    # line_width=2,  # Thickness of the lines and bounding boxes (√âpaisseur des lignes et des cadres de d√©limitation)\n",
    "    # classes=[0, 2],  # count specific classes i.e. person and car with COCO pretrained model (compter des classes sp√©cifiques, c'est-√†-dire la personne et la voiture avec le mod√®le pr√©-entra√Æn√© COCO)\n",
    "    # tracker=\"botsort.yaml\",  # choose trackers i.e \"bytetrack.yaml\" (choisir des trackers, par exemple ¬´¬†bytetrack.yaml¬†¬ª)\n",
    ")\n",
    "\n",
    "# Process video frames in a loop (Traiter les images vid√©o en boucle)\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    # Use the Object Counter to count objects in the frame and get the annotated image (Utiliser le compteur d'objets pour compter les objets dans l'image et obtenir l'image annot√©e)\n",
    "    results = counter(im0)\n",
    "\n",
    "    # Write the annotated frame to the output video (√âcrire l'image annot√©e dans la vid√©o de sortie)\n",
    "    video_writer.write(results.plot_im)\n",
    "\n",
    "# Release the video capture and writer objects (Lib√©rer les objets de capture et de gravure vid√©o)\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "\n",
    "# Close all OpenCV windows (Fermer toutes les fen√™tres OpenCV)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comptage-pneu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
